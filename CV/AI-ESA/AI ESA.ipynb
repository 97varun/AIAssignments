{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "works\n",
      "11321\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "root = 'C:/Users/Varun/Desktop/VOCdevkit/VOC2010'\n",
    "ann_dir = os.path.join(root, 'Annotations')\n",
    "ann_file_list = os.listdir(ann_dir)\n",
    "raw_dataset = []\n",
    "for file in ann_file_list :\n",
    "    e = ET.parse(root + '/Annotations/' + file).getroot()\n",
    "    class_name = \"\"\n",
    "    big_box = 0\n",
    "    for child in e :\n",
    "        if child.tag == 'object' :\n",
    "            for grandchild in child :\n",
    "                if grandchild.tag == 'name' :\n",
    "                    name = grandchild.text\n",
    "                if grandchild.tag == 'bndbox' :\n",
    "                    d = {}\n",
    "                    for greatgrandchild in grandchild :\n",
    "                        d[greatgrandchild.tag] = int(greatgrandchild.text)\n",
    "                    temp = abs(d[\"xmax\"] - d[\"xmin\"]) * abs(d[\"ymax\"] - d[\"ymin\"])\n",
    "                    if temp > big_box :\n",
    "                        big_box = temp\n",
    "                        class_name = name\n",
    "    k = [file, class_name]\n",
    "    raw_dataset.append(k[:])\n",
    "print('works')\n",
    "print(len(raw_dataset))\n",
    "# print(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tvmonitor': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]), 'sheep': array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'bicycle': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'boat': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'motorbike': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), 'sofa': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]), 'cow': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), 'train': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]), 'dog': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]), 'horse': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]), 'pottedplant': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]), 'bus': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'aeroplane': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'bird': array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'diningtable': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]), 'person': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cat': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'car': array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'bottle': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'chair': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "one_hot_rep = {'person': np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'sheep': np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'aeroplane': np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'bicycle': np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'bird': np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'boat': np.array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'bottle': np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'bus': np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'car': np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cat': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'chair': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'cow': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]), 'diningtable': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]), 'dog': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]), 'horse': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]), 'motorbike': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), 'pottedplant': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]), 'sofa': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]), 'train': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]), 'tvmonitor': np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])}\n",
    "print(len(one_hot_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11321\n",
      "[('2007_000027.xml', array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), ('2007_000032.xml', array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), ('2007_000033.xml', array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), ('2007_000039.xml', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])), ('2007_000042.xml', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])), ('2007_000061.xml', array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), ('2007_000063.xml', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])), ('2007_000068.xml', array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), ('2007_000121.xml', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])), ('2007_000123.xml', array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]))]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy as dp\n",
    "pre_x_master = []\n",
    "for file, class_name in raw_dataset :\n",
    "    temp = file, one_hot_rep[class_name]\n",
    "    pre_x_master.append(dp(temp))\n",
    "print(len(pre_x_master))\n",
    "# print(pre_x_master[:10])\n",
    "del raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11321\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "root_dir = 'C:/Users/Varun/Desktop/VOCdevkit/VOC2010'\n",
    "img_dir = os.path.join(root_dir, 'JPEGImages')\n",
    "\n",
    "def load_img(img_filename):\n",
    "    tmp_img = Image.open(os.path.join(img_dir, img_filename))\n",
    "    tmp_img.thumbnail((128, 128), Image.ANTIALIAS)\n",
    "    return np.array(tmp_img)\n",
    "    \n",
    "all_images = os.listdir(img_dir)\n",
    "\n",
    "MAX_X = MAX_Y = 128\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for img_name, y_val in pre_x_master :\n",
    "    img_name = img_name[:-3] + 'jpg'\n",
    "    img_arr = load_img(img_name)\n",
    "    img_x, img_y = img_arr.shape[0], img_arr.shape[1]\n",
    "    img_arr = img_arr.astype('float32')\n",
    "    pad_x = (MAX_X - img_x)\n",
    "    pad_y = (MAX_Y - img_y)\n",
    "    odd_x = pad_x & 1\n",
    "    odd_y = pad_y & 1\n",
    "    pad_x //= 2\n",
    "    pad_y //= 2\n",
    "    \n",
    "    img_arr = np.pad(img_arr, [(pad_x + odd_x, pad_x), (pad_y + odd_y, pad_y), (0, 0)], mode = 'constant', constant_values = 0)\n",
    "    k = [img_arr/255.0, y_val]\n",
    "    dataset.append(dp(k))\n",
    "    \n",
    "#     img = Image.fromarray(img_arr, 'RGB')\n",
    "#     img.save('sample.jpg')\n",
    "#     img.show()\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "print(dataset_size)\n",
    "del pre_x_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array(dataset)\n",
    "indices = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "dataset = dataset[indices]\n",
    "\n",
    "x_master, y_master = [], []\n",
    "for x, y in dataset[:8000] :\n",
    "    x_master.append(x)\n",
    "    y_master.append(y) \n",
    "x_master = np.array(x_master)\n",
    "y_master = np.array(y_master)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 128, 128, 3) (8000, 20) 2000\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_SPLIT = 0.25\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * x_master.shape[0])\n",
    "\n",
    "print(x_master.shape, y_master.shape, nb_validation_samples)\n",
    "\n",
    "x_train = x_master[:-nb_validation_samples]\n",
    "y_train = y_master[:-nb_validation_samples]\n",
    "x_val = x_master[-nb_validation_samples:]\n",
    "y_val = y_master[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 47s 8ms/step - loss: 2.7704 - acc: 0.2390 - val_loss: 2.7055 - val_acc: 0.2360\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 46s 8ms/step - loss: 2.6181 - acc: 0.2512 - val_loss: 2.5245 - val_acc: 0.2525\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 46s 8ms/step - loss: 2.5342 - acc: 0.2680 - val_loss: 2.5508 - val_acc: 0.2595\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 46s 8ms/step - loss: 2.4613 - acc: 0.2727 - val_loss: 2.3925 - val_acc: 0.2840\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 46s 8ms/step - loss: 2.3669 - acc: 0.2958 - val_loss: 2.3394 - val_acc: 0.2915\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 46s 8ms/step - loss: 2.3004 - acc: 0.3033 - val_loss: 2.2336 - val_acc: 0.3120\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 46s 8ms/step - loss: 2.2122 - acc: 0.3257 - val_loss: 2.2977 - val_acc: 0.3095\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 46s 8ms/step - loss: 2.1522 - acc: 0.3320 - val_loss: 2.1807 - val_acc: 0.3365\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 46s 8ms/step - loss: 2.0924 - acc: 0.3448 - val_loss: 2.1401 - val_acc: 0.3465\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 46s 8ms/step - loss: 2.0091 - acc: 0.3630 - val_loss: 2.1424 - val_acc: 0.3405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2b77d2da0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "NUM_CLASSES = 20\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(128, 128, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs = 10,\n",
    "          validation_data = [x_val, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1071263933181763, 0.34200000539422037]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, y_test = [], []\n",
    "for x, y in dataset[-500:] :\n",
    "    x_test.append(x)\n",
    "    y_test.append(y) \n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model.evaluate(x_test, y_test, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected conv2d_23_input to have shape (None, 3, 32, 32) but got array with shape (1, 128, 128, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-597203715764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclass_name_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2010_003101.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-61-597203715764>\u001b[0m in \u001b[0;36mpredict_class\u001b[1;34m(model, filename)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclass_name_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1763\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1764\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1765\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    151\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected conv2d_23_input to have shape (None, 3, 32, 32) but got array with shape (1, 128, 128, 3)"
     ]
    }
   ],
   "source": [
    "class_name_dict = {0: 'person', 1: 'sheep', 2: 'aeroplane', 3: 'bicycle', 4: 'bird', 5: 'boat', 6: 'bottle', 7: 'bus', 8: 'car', 9: 'cat', 10: 'chair', 11: 'cow', 12: 'diningtable', 13: 'dog', 14: 'horse', 15: 'motorbike', 16: 'pottedplant', 17: 'sofa', 18: 'train', 19: 'tvmonitor'}\n",
    "\n",
    "def predict_class(model, filename) :\n",
    "    img_arr = load_img(filename)\n",
    "    img_x, img_y = img_arr.shape[0], img_arr.shape[1]\n",
    "    img_arr = img_arr.astype('float32')\n",
    "    pad_x = (MAX_X - img_x)\n",
    "    pad_y = (MAX_Y - img_y)\n",
    "    odd_x = pad_x & 1\n",
    "    odd_y = pad_y & 1\n",
    "    pad_x //= 2\n",
    "    pad_y //= 2\n",
    "    img_arr = np.pad(img_arr, [(pad_x + odd_x, pad_x), (pad_y + odd_y, pad_y), (0, 0)], mode = 'constant', constant_values = 0)    \n",
    "    l = [img_arr]\n",
    "    l = np.array(l)\n",
    "    ans = model.predict(l)\n",
    "    return class_name_dict[np.argmax(ans)]\n",
    "\n",
    "print(predict_class(model2, os.path.join(img_dir, '2010_003101.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 3, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3, 32, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 3, 32, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 291,412\n",
      "Trainable params: 291,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/8\n",
      "6000/6000 [==============================] - 47s 8ms/step - loss: 0.9495 - acc: 0.6710 - val_loss: 2.6738 - val_acc: 0.3620\n",
      "Epoch 2/8\n",
      "6000/6000 [==============================] - 47s 8ms/step - loss: 0.8692 - acc: 0.6992 - val_loss: 2.8124 - val_acc: 0.3550\n",
      "Epoch 3/8\n",
      "6000/6000 [==============================] - 47s 8ms/step - loss: 0.8084 - acc: 0.7090 - val_loss: 2.7728 - val_acc: 0.3590\n",
      "Epoch 4/8\n",
      "6000/6000 [==============================] - 47s 8ms/step - loss: 0.8071 - acc: 0.7158 - val_loss: 2.9855 - val_acc: 0.3675\n",
      "Epoch 5/8\n",
      "6000/6000 [==============================] - 47s 8ms/step - loss: 0.7264 - acc: 0.7447 - val_loss: 3.1155 - val_acc: 0.3715\n",
      "Epoch 6/8\n",
      "6000/6000 [==============================] - 47s 8ms/step - loss: 0.7267 - acc: 0.7478 - val_loss: 3.0913 - val_acc: 0.3660\n",
      "Epoch 7/8\n",
      "6000/6000 [==============================] - 47s 8ms/step - loss: 0.7052 - acc: 0.7585 - val_loss: 3.2077 - val_acc: 0.3575\n",
      "Epoch 8/8\n",
      "6000/6000 [==============================] - 47s 8ms/step - loss: 0.6686 - acc: 0.7680 - val_loss: 3.2665 - val_acc: 0.3680\n",
      "Accuracy: 37.80%\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "# Compile model2\n",
    "epochs = 8\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model2.summary())\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
